% This is a variation of the NeurIPS'24 format
\documentclass{article}
\usepackage[final]{adrl}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{url}
\usepackage{xcolor}     
\usepackage{spreadtab}

\newcommand{\TODO}[1][]{\textcolor{red}{\bf [TODO]}}

\title{ADRL Project Proposal Self-Grading}
\author{Jan Malte TÃ¶pperwien \\ \url{https://github.com/CrunchyFlakes/Novelty-Guided-Proximal-Curriculum-Learning}}

\begin{document}

\maketitle

You should score your own work in each of these categories from 0-10 points per question. 0 in this case is "did not do this at all" and 10 is "did this perfectly".
The tables will autocomplete your score for each category and you can then decide from these scores how you would grade yourself in total.

You don't have to completely follow our points in grading yourself, but as an orientation: 100-95\% would be equivalent to 1.0, 95-90\% to 1.3 and so on. 
We would furthermore weight the categories as follows: 15\% research understanding, 30\% idea \& implementation, 30\% empirical evaluation and 25\% writing. 
This is also only a guideline and you don't need to follow it exactly.

\section{Research Understanding}

\begin{spreadtab}{{tabular}{|l|c|c||c|}}
\hline
    @ Question & @ Points given & @ Weight & @ Point Total \\
    \hline
    \hline
    @ I described the task setting of my problem well & 9 & 0.3 & b2 * c2\\
    \hline
    @ I referenced the most important work within that task setting & 8 & 0.3 & b3 * c3\\
    \hline
    @ At least 3 of my references were not in the lecture slides & 10 & 0.3 & b4 * c4\\
    \hline
    @ I provided references on similar approaches with other objectives & 9 & 0.1 & b5 * c5\\
    \hline
    \hline
    @ Result & b2+b3+b4+b5 & c2+c3+c4+c5 & d2+d3+d4+d5 \\
\hline
\end{spreadtab}

\section{Idea \& Implementation}

\begin{spreadtab}{{tabular}{|l|c|c||c|}}
\hline
    @ Question & @ Points given & @ Weight & @ Point Total \\
    \hline
    \hline
    @ My idea is small enough to explore in this project & 9 & 0.2 & b2 * c2\\
    \hline
    @ I can express my idea in 1-3 research questions & 9 & 0.3 & b3 * c3\\
    \hline
    @ My idea is based on concepts from the lecture & 9 & 0.1 & b5 * c5\\
    \hline
    @ My idea is new in the setting I consider & 8 & 0.1 & b5 * c5\\
    \hline
    @ My implementation can be compared to state-of-the-art approaches & 8 & 0.2 & b4 * c4\\
    \hline
    @ I provide good quality code for my idea & 9 & 0.1 & b5 * c5\\
    \hline
    \hline
    @ Result & b2+b3+b4+b5+b6+b7 & c2+c3+c4+c5+c6+c7 & d2+d3+d4+d5+d6+d7 \\
\hline
\end{spreadtab}

\textbf{Open Question:} How do you score the long-term impact of your idea? What does it contribute to the research landscape overall?

\textbf{Answer:}

The main contribution of this idea is to see how different curriculum learning approaches can be combined.
As far as I know/have found there does not exist that much research on combining different approaches in the realm of curriculum learning.
Usually someone has a new idea that sometimes does resemble an old one, but interactions of different approaches are not researched and talked about.

Concerning the longevity of this idea, it is probably not that important because proximal curriculum learning itself is not even known or cited well and in this form is only applicable to environments providing the setting of the starting state. 
But it may help to motivate researchers to study interactions between different approaches and to get an intuition on how well these interactions perform.

It also helps to provide new information regarding curriculum learning approaches that let the agent itself define the speed at which harder tasks are given to it.
A lot of approaches seemed to just give a rigid schedule, although there are other approaches out there.


\section{Empirical Evaluation}

\begin{spreadtab}{{tabular}{|l|c|c||c|}}
\hline
    @ Question & @ Points given & @ Weight & @ Point Total \\
    \hline
    \hline
    @ My experiments all aim to answer my research questions & 9 & 0.3 & b2 * c2\\
    \hline
    @ I follow the experimental standards from the lecture & 8 & 0.3 & b3 * c3\\
    \hline
    @ I ensure reproducibility as much as I can & 9 & 0.3 & b4 * c4\\
    \hline
    @ All my results are shown with confidence intervals & 10 & 0.1 & b5 * c5\\
    \hline
    \hline
    @ Result & b2+b3+b4+b5 & c2+c3+c4+c5 & d2+d3+d4+d5 \\
\hline
\end{spreadtab}

\textbf{Open Question:} Are there parts of your research questions you were not able to address empirically? Which ones?

\textbf{Answer:}

Due to time constraints:

1. Are the picked starting states plausible? \\
Heat maps/distributions over time of the starting states would be nice to evaluate the plausibility of the picked states.
This would be interesting for the novelty and curriculum distribution independently and both combined.
Using this approach one could probably also answer the question why the combined approach does not always perform well.

2. Are the picked hyperparameters good? \\
This could be answered by running hyperparameter optimization for longer and/or incorporating a multi-fidelity approach.

3. Do other state novelty approaches work better/worse? \\
This could shed more light on interactions between approaches.

4. Is a well-picked pool of starting states better and how to pick it? \\
This may lower computational costs and improve performance.


\section{Writing}

\begin{spreadtab}{{tabular}{|l|c|c||c|}}
\hline
    @ Question & @ Points given & @ Weight & @ Point Total \\
    \hline
    \hline
    @ My writing is clear and understandable & 9 & 0.2 & b2 * c2\\
    \hline
    @ I explain all concepts someone from the RL1 lecture might not know & 10 & 0.2 & b3 * c3\\
    \hline
    @ I have a reference or empirical insight for each claim & 9 & 0.3 & b4 * c4\\
    \hline
    @ Where necessary, I use figures to illustrate my ideas & 7 & 0.1 & b5 * c5\\
    \hline
    @ The spelling and formatting is good and supports readability & 9 & 0.2 & b5 * c5\\
    \hline
    \hline
    @ Result & b2+b3+b4+b5+b6 & c2+c3+c4+c5+c6 & d2+d3+d4+d5+d6 \\
\hline
\end{spreadtab}

\textbf{Open Question:} Do you think your write-up accurately reflects the work you did? Why or why not?

\textbf{Answer:}

Interpreting work as the scientific part of the project: \\
I think it does, because it accurately reflects my idea of how to combine the approaches and aggregates most of the knowledge/data I have gotten about the idea.
It also provides my thoughts on shortcomings and strenghts of the approach.
Both of these points at least to an amount possible in 5 pages.

Interpreting work as how the time was spent on the project: \\
Not really, because most of the time was invested in setting up hpo and getting MiniGrid and Stable-Baselines to do what I want. 
Especially resetting the environments while picking starting states and feeding the agents information into the environment was something that neither of the libraries really supported.
A lot less time was spent on the actual idea, researching related work and evaluation.

\section{Final Grade}
\textbf{Summary Statement:} 
\emph{Add 2-3 sentences about strengths and weaknesses of the project and why you think the grade is correct.}

Strengths: The idea to test interactions between these approaches was good and trying to use it to solve sparse reward settings was reasonable. \\
Weaknesses: Not a lot of illustrations/graphs were generated and the embedding into the research landscape may have been incomplete.

This grade is correct, because, given the scope, a novel idea was implemented extensively using multiple contemporary approaches without using that much existing code and evaluated scientifically with ideas to extend the idea further.

\textbf{Final grade} 1.0
\end{document}
