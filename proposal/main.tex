% This is a variation of the NeurIPS'24 format
\documentclass{article}
\usepackage[final]{adrl}

\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}     
\usepackage{algorithm}
\usepackage{algpseudocode}

% Add your own as neccessary

\title{Novelty-Guided Proximal Curriculum Learning}
\author{Jan Malte TÃ¶pperwien \\ \url{https://github.com/CrunchyFlakes/Novelty-Guided-Proximal-Curriculum-Learning?tab=readme-ov-file#editing-this-readme}}

\begin{document}

\maketitle
\begin{abstract}
    An abstract is a short summary of your project. It should really only be a single paragraph, not much more than 10 lines.
\end{abstract}
\section{Introduction}
Reinforcement learning (RL) has shown to be able to solve difficult tasks in simulated environments (\citep{human_level_control}, \citep{continuous_control}, \citep{rl_go}). However, to solve real-world problems an agent has to often solve problems which exhibit large action- and state spaces, sparse rewards and changing tasks to get to a goal. This poses the problem of exploring these spaces and, even with good exploration getting close to the goal, the agent often does not get a reward due to the sparsity of these. Additionaly, training data gathering on real-world problems through e.g. simulation is often expensive and exploration therefore has to be done efficiently.

One proposed method to tackle this problem is \textit{curriculum learning}~\citep{curr}. Curriculum learning applies the pedagogical idea of giving a student increasingly difficult tasks to RL algorithms. This allows agent to get to the reward more often on easier tasks and only after that to progress to more difficult tasks, which would have previously led to seldom rewards at best. By choosing a proper curriculum one also lowers the amount of needed environment steps, by only generating data which actually lets the agent learn. \\
A possibility to implement curriculum learning is by setting the starting state closer to the goal and increasing this distance over the course of training. One approach to measure this distance is given by \cite{prox_curr}, where they measure the difficulty of the task by using the value function of the agent and proceed to give the agent tasks appropriate to its current learning progress. One weakness of this approach is, that at the beginning of learning the value function has not converged to proper values and therefore unsuitable starting states may be chosen.

To explore the state space, \textit{state novelty} methods like random network distillation~\citep{rnd} have proven to be successfull in steering the agent towards underexplored states. This is usually done by adding an intrinsic reward to the agent for finding new states.

This work aims to combine curriculum learning as done in \cite{prox_curr} with random network distillation~\citep{rnd}. By setting starting states also based on state novelty, the state space is properly explored from the beginning. This is crucial to let the agent properly explore the state space and overcome the random initialization of the value function, leading to proper curriculum learning.

\section{Related Work}
Here you cite related papers, either by referring to \cite{parkerholder-jair22} or as a reference at the end of the sentence~\citep{parkerholder-jair22}. 
Add your references to the "references.bib" file. 
Pay attention: if you get the citation from arxiv, it will only give you that version - but you should cite the published one if it exists! 
Therefore you should look for the paper on dblp.org and use that citation. 
You can delete things like the bibsource and timestamp, but keep the important information like authors, title, journal, year or DOI.

\section{Approach}
This is where you describe what you did. Good things to include are {\color{orange} colorcoding}, pseudocode as in Algorithm~\ref{alg:code} and equations like in Equation~\ref{eq:pi}.

\begin{algorithm}[H]
    \caption{A great RL algorithm.}
    \label{alg:code}
    \begin{algorithmic}
        \Require environment $e$, algorithm $A$
        \Return policy $\pi$
        \While TRUE
            \State Train $A$ on $e$
        \EndWhile
    \end{algorithmic}
\end{algorithm}

\begin{equation}
    \label{eq:pi}
    \pi \in \Pi, \pi: \mathcal{S} \mapsto \mathcal{A}
\end{equation}

\section{Experiments}
Here are your results and their description. Some things to look out for:
\begin{itemize}
    \item Use a high dpi when plotting
    \item Even better: plot SVGs and use the corresponding LaTeX package to include them
    \item Don't make me zoom in to read your axis descriptions!
\end{itemize}

\section{Discussion}
Here you recap what you did, say what worked and what didn't and point towards future work.
Make sure to include both immediate future work (i.e. what's left to make this a full 4-page workshop paper) and long-term future work (i.e. how to build on your ideas and results in the future).

% Everything from this point on does not count towards your page count
\newpage
\bibliography{references}
\bibliographystyle{plainnat}

\newpage
\section*{Checklist}
%Please fill this out to check the validity of your writeup. Options are:
% \answerYes{}
% \answerNo{}
% \answerNA{}
\begin{enumerate}

\item General points:
\begin{enumerate}
  \item Do the main claims made in the abstract and introduction accurately reflect your contributions and scope?
    \answerTODO{}
  \item Did you cite all relevant related work?
    \answerTODO{}
  \item Did you describe the limitations of your work?
    \answerTODO{}
  \item Did you include a discussion of future work?
    \answerTODO{}
\end{enumerate}

\item If you are including theoretical results...
\begin{enumerate}
  \item Did you state the full set of assumptions of all theoretical results?
    \answerTODO{}
	\item Did you include complete proofs of all theoretical results?
    \answerTODO{}
\end{enumerate}

\item If you ran experiments (e.g. for benchmarks)...
\begin{enumerate}
  \item Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)?
    \answerTODO{}
  \item Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)?
    \answerTODO{}
  \item Did you run at least 5 repetitions of your method?
    \answerTODO{}
  \item Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)?
    \answerTODO{}
  \item Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)?
    \answerTODO{}
\end{enumerate}

\item If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...
\begin{enumerate}
  \item If your work uses existing assets, did you cite the creators?
    \answerTODO{}
  \item Did you make sure the license of the assets permits usage?
    \answerTODO{}
  \item Did you reference the assets directly within your code and repository?
    \answerTODO{}
\end{enumerate}
\end{enumerate}
\end{document}
